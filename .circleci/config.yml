# Use 2.1 for orbs
version: 2.1

# -------------------------------------------------------------------------------------
# Environments to run the jobs in
# -------------------------------------------------------------------------------------
gpu: &gpu
  environment:
    CUDA_VERSION: "11.4"
  machine:
    image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.medium.multi


# -------------------------------------------------------------------------------------
# Re-usable commands
# -------------------------------------------------------------------------------------
cache_key: &cache_key cache-key-{{ checksum ".circleci/config.yml" }}-{{ checksum "setup.py"}}

install_dep_common: &install_dep_common
  - run:
      name: Install Common Dependencies
      command: |
        source $BASH_ENV
        source activate fairseq-20221101
        pip install "flake8==3.9.2" "black==22.3.0" "transformers" "pyarrow" "boto3" "pandas" "protobuf==3.20.2" "aim>=3.9.4" "azure-storage-blob" "click==8.0.4" "cython" "dataclasses" "editdistance" "fire" "flask==2.1.1" "hydra-core==1.1.0" "ipdb" "ipython" "Jinja2==3.1.1" "markupsafe" "more_itertools" "mypy" "ninja" "numpy" "omegaconf==2.1.1" "portalocker>=2.5" "pre-commit" "pytest" "pytest-regressions" "regex" "scikit-learn" "sacrebleu" "tensorboard==2.8.0" "timeout-decorator" "tokenizers" "tqdm" "typing_extensions" "bitarray" "sacremoses" "sentencepiece" "pybind11" "pyre-extensions==0.0.23" "typing-inspect==0.8.0" "iopath"
        
        # install cudatoolkit to enable sequence_parallel 
        conda install cudatoolkit

        # Need to install ninja build system
        sudo apt-get update
        sudo apt-get install ninja-build

install_dep_fused_ops: &install_dep_fused_ops
  - run:
      name: Install Megatron/Apex Dependencies
      working_directory: ~/
      command: |
        source $BASH_ENV
        source activate fairseq-20221101
        if ! python -c 'import apex'; then
          git clone --recursive https://github.com/NVIDIA/apex.git
          cd apex
          # skip the part of the setup.py code with the warning about
          # cuda versions mismatch
          sed -i '32 i \ \ \ \ return' setup.py
          pip install -v --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" --global-option="--deprecated_fused_adam" --global-option="--xentropy" --global-option="--fast_multihead_attn" ./
          cd ~/
        fi
        if ! python -c 'import megatron_lm'; then
          git clone --depth=1 --branch fairseq_v3 https://github.com/ngoyal2707/Megatron-LM.git
          cd Megatron-LM
          pip install -e .
          cd ~/
        fi

#Remove this when we get a new fairscale release
install_fairscale: &install_fairscale
  - run:
      name: Install Fairscale from Source
      working_directory: ~/
      command: |
        source $BASH_ENV
        source activate fairseq-20221101
        if ! python -c 'import fairscale'; then
            git clone https://github.com/facebookresearch/fairscale.git
            cd fairscale
            git checkout ngoyal_bf16_changes
            pip install --no-build-isolation -e .
            cd ~/
        fi

install_dep_pt19: &install_dep_pt19
  - run:
      name: Install Pytorch Dependencies
      working_directory: ~/
      command: |
        source $BASH_ENV
        source activate fairseq-20221101
        pip install --upgrade setuptools
        pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116
        python -c 'import torch; print("Torch version:", torch.__version__)'

install_repo: &install_repo
  - run:
      name: Install Repository
      working_directory: ~/
      command: |
        source $BASH_ENV
        source activate fairseq-20221101
        if ! python -c 'import fairscale'; then
            git clone git@github.com:facebookresearch/metaseq.git
            cd metaseq
            pip install --no-build-isolation -e .
            cd ~/
        fi

check_nvidia_driver: &check_nvidia_driver
  - run:
      name: Check NVIDIA Driver
      working_directory: ~/
      command: |
        pyenv versions
        nvidia-smi
        uname -m

create_conda_env: &create_conda_env
  run:
      name: Install and Create Conda Environment
      command: |
        curl -o ~/miniconda.sh -O  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
        chmod +x ~/miniconda.sh
        bash ~/miniconda.sh -b -p $HOME/miniconda
        rm ~/miniconda.sh
        echo 'export PATH=$HOME/miniconda/bin:$PATH' >> $BASH_ENV
        source $BASH_ENV
        if [ ! -d ~/miniconda/envs/fairseq-20221101 ]
        then
          conda create --name fairseq-20221101 python=3.9 -y
        fi
        source activate fairseq-20221101
        python --version
        pip install --upgrade pip
        conda install -y conda-pack

update_cuda: &update_cuda
  run:
    name: Update the cuda version
    working_directory: ~/
    command: |    
      # download and update the keys for cuda repo
      wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
      sudo dpkg -i cuda-keyring_1.0-1_all.deb  
      
      # download the .pin file to setup cuda
      wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
      sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub
      sudo add-apt-repository "deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /"
      
      # install cuda
      sudo apt update
      sudo apt install cuda-toolkit-11.6
      sudo apt install cuda
      
      # set path to point to CUDA binaries
      echo 'export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}' >> ~/.bashrc
      
      # check th version
      nvcc --version
      nvidia-smi
      cat ~/.bashrc 


download_and_configure_125m_with_hf_dependencies: &download_and_configure_125m_with_hf_dependencies
  - run:
      name: Download and configure a 125m checkpoint with HF dependencies
      working_directory: ~/metaseq/gpu_tests
      command: |
        source $BASH_ENV
        source activate fairseq-20221101
        wget https://dl.fbaipublicfiles.com/opt/test_artifacts/125m_with_hf_dependencies.tar.gz
        tar -xvzf ./125m_with_hf_dependencies.tar.gz -C .
        python -m metaseq.scripts.convert_to_singleton ./125m
        python -m transformers.models.opt.convert_opt_original_pytorch_checkpoint_to_pytorch --pytorch_dump_folder_path ./125m/ --hf_config ./125m/config.json --fairseq_path ./125m/restored.pt 

commands:

  gpu_pre: &gpu_pre
    steps:
      - run:
          name: Setup Ramdisk
          command: sudo mount -t tmpfs tmpfs ~/
      - checkout
      - <<: *check_nvidia_driver
      - <<: *update_cuda
      - <<: *create_conda_env
      - restore_cache:
          key: *cache_key

  gpu_post: &gpu_post
    steps:
      - <<: *install_dep_common
      - <<: *install_fairscale
      - <<: *install_dep_fused_ops
      - <<: *install_repo
      - <<: *download_and_configure_125m_with_hf_dependencies
      - save_cache:
          paths:
            - ~/miniconda/envs/fairseq-20221101/lib/python3.9/site-packages
          key: *cache_key
      - run:
          name: Run Unit Tests
          command: |
            source $BASH_ENV
            source activate fairseq-20221101
            python -m pytest --junitxml=test-results/junit.xml gpu_tests
      - store_test_results:
          path: test-results

# -------------------------------------------------------------------------------------
# Jobs to run
# -------------------------------------------------------------------------------------

jobs:

  gpu_tests_pt19:
    <<: *gpu

    working_directory: ~/metaseq

    steps:
      - gpu_pre
      - <<: *install_dep_pt19
      - gpu_post


workflows:
  version: 2
  build:
    jobs:
      - gpu_tests_pt19